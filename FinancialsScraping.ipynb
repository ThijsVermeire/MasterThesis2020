{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Date Scraping\n",
    "**_TABLE OF CONTENT_**\n",
    "1. Installs, imports and Inputs  \n",
    "    - Import \n",
    "    - Input \n",
    "2. Financial Data extraction  \n",
    "    - Connect and write to database\n",
    "    - Scrape Financials\n",
    "3. Macro-Economic indicators extraction\n",
    "    - Crude OIL, Treasury and Internation indices\n",
    "    - Libor Data \n",
    "    - Write Fundamentals \n",
    "\n",
    "***\n",
    "## 1. imports and Inputs\n",
    "\n",
    "### 1.1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "from urllib.error import HTTPError\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import psycopg2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Inputs\n",
    "- Read all ticker symbols:\n",
    "    - List of the 20 companies with the highest market capitalization in the NYSE\n",
    "- Read in list of all wanted fundamental indicators\n",
    "\n",
    ">Date of composition 25/09/2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create connection with database\n",
    "def get_connection():\n",
    "    connection = psycopg2.connect(user = \"postgres\",\n",
    "                                  password = \"postgres\",\n",
    "                                  host = \"localhost\",\n",
    "                                  port = \"5432\",\n",
    "                                  database = \"postgres\")\n",
    "    return connection\n",
    "\n",
    "#Close connection with database\n",
    "def close_connection(connection):\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"Postgres connection is closed\")\n",
    "\n",
    "# Retrieves tickers from database, returns an array of strings\n",
    "def get_tickers():\n",
    "    tickers = []\n",
    "    try:\n",
    "        connection = get_connection()\n",
    "        cursor = connection.cursor()\n",
    "        select_query = \"\"\"select ticker from companies\"\"\"\n",
    "        cursor.execute(select_query,)\n",
    "        records = cursor.fetchall()\n",
    "        for row in records:\n",
    "            tickers.append(row[0])\n",
    "        close_connection(connection)\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while getting data\", error)\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Initial reading to insert into database\n",
    "#Writes to companies db and include: company name, symbol, size and sector\n",
    "def write_companies():\n",
    "    df = pd.read_csv(\"Companies.csv\")\n",
    "    try:\n",
    "       connection = get_connection()\n",
    "       cursor = connection.cursor()\n",
    "\n",
    "       postgres_insert_query = \"\"\" INSERT INTO companies (ticker, name , sector, size) VALUES (%s,%s,%s,%s)\"\"\"\n",
    "       i = 0\n",
    "       for i in range(len(df.Name)):\n",
    "           record_to_insert = (df['Ticker'][i], df['Name'][i], df['Sector'][i], df['Size'][i])\n",
    "           cursor.execute(postgres_insert_query, record_to_insert)\n",
    "\n",
    "           connection.commit()\n",
    "           count = cursor.rowcount\n",
    "           print (count, \"Record inserted successfully into Companies table\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        if(connection):\n",
    "            print(\"Failed to insert record into Companies table\", error)\n",
    "\n",
    "    finally:\n",
    "        # Closing database connection.\n",
    "        close_connection(connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "## 2. Financial Data extraction\n",
    "### 2.1 Connect and write to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Writes new financial data to database\n",
    "def write_financials(df):\n",
    "    try:\n",
    "        connection = get_connection()\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\" INSERT INTO financials (ticker, date , open, close, volume , adjclose, high , low) VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "        record_to_insert = (df['Ticker'][0],df[\"Date\"][0], float(df['Open'][0]),float( df['Close'][0]), int(df['Volume'][0]),float(df['Adj Close'][0]), float(df['High'][0]), float(df['Low'][0]))\n",
    "        cursor.execute(postgres_insert_query,record_to_insert)\n",
    "        connection.commit()\n",
    "        close_connection(connection)\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while getting data \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scrape financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Run Daily to insert into database, run below\n",
    "def financials_main():\n",
    "    for ticker in get_tickers():\n",
    "         #Use yfinance to download financials\n",
    "        df = yf.download(ticker, date.today())\n",
    "        # Add scraped ticker symbol to financials\n",
    "        df['Ticker'] = ticker\n",
    "        # Reset index, date index becomes normal column\n",
    "        df = df.reset_index()\n",
    "        # Write to database\n",
    "        write_financials(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Macro-Economic indicators extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Crude OIL, Treasury and Internation indices\n",
    " From Yahoo finance the following can be scraped\n",
    "   - Crude oil CL=F\n",
    "   - Brent Crude Oil: BZ= F\n",
    "   - 13 week US Treasury Bill: ^IRX\n",
    "   - Treasury Yield 5 Years: ^FVX\n",
    "   - Treasury Yield 10 Years: ^TNX\n",
    "   - Treasury Yield 30 Years: ^TYX\n",
    "   - USD/EUR: EUR= X\n",
    "   - USD/GBP: GBP= X\n",
    "   - USD/MXN: MXN= X\n",
    "   - USD/CNY: CNY= X\n",
    "   - USD/JPY: JPY= X\n",
    "   - USD/CAD: CAD= X\n",
    "   - Gold\n",
    "   - Bitcoin\n",
    "   - DAX\n",
    "   - Dow Jones Index\n",
    "   - Nikkei Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_macro_economics(df):\n",
    "    yesterday = datetime.datetime.today() + timedelta(-1)\n",
    "    try:\n",
    "        #Create connection with database\n",
    "        connection = get_connection()\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\" INSERT INTO macro_economic (date, crude_oil, brent_crude_oil,\n",
    "        thirtheen_week_treasury_bill, treasury_yield_five, treasury_yield_ten,\n",
    "        treasury_yield_thirty, dji, dax, nikkei, gold, bitcoin, usd_eur, usd_gbp, usd_cad,\n",
    "        usd_jpy, usd_cny, usd_aud, usd_mxn)\n",
    "        VALUES (%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s)\"\"\"\n",
    "        record_to_insert = (yesterday, df['CrudeOil'][0],df[\"BrentOil\"][0],\n",
    "                            df['ThirtheenWeekTB'][0], df['TreasuryYieldFiveYears'][0],\n",
    "                            df['TreasuryYieldTenYears'][0],df['TreasuryYieldThirtyYears'][0],\n",
    "                            df['DJI'][0], df['DAX'][0], df['NI225'][0], df['Gold'][0],\n",
    "                            df['Bitcoin'][0], df['USD/EUR'][0], df['USD/GBP'][0], df['USD/CAD'][0],\n",
    "                            df['USD/JPY'][0], df['USD/CNY'][0], df['USD/AUD'][0], df['USD/MXN'][0])\n",
    "        cursor.execute(postgres_insert_query,record_to_insert)\n",
    "        connection.commit()\n",
    "        close_connection(connection)\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while getting data \", error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def macro_economic_main():\n",
    "    df = yf.download('CL=F', date.today()).rename(columns = {'Close':'CrudeOil'})\n",
    "    macro = pd.DataFrame(df['CrudeOil'])\n",
    "    macro['BrentOil'] = pd.DataFrame(yf.download('BZ=F', date.today())).Close\n",
    "    macro['ThirtheenWeekTB'] = pd.DataFrame(yf.download('^IRX', date.today())).Close\n",
    "    macro['TreasuryYieldFiveYears'] = pd.DataFrame(yf.download('^FVX', date.today())).Close\n",
    "    macro['TreasuryYieldTenYears']  = pd.DataFrame(yf.download('^TNX', date.today())).Close\n",
    "    macro['TreasuryYieldThirtyYears'] = pd.DataFrame(yf.download('^TYX', date.today())).Close\n",
    "#     macro['ThirtheenWeekTB'] = np.NaN\n",
    "#     macro['TreasuryYieldFiveYears'] = np.NaN\n",
    "#     macro['TreasuryYieldTenYears']  = np.NaN\n",
    "#     macro['TreasuryYieldThirtyYears'] = np.NaN\n",
    "    macro['DJI'] = pd.DataFrame(yf.download('^DJI', date.today())).Close[0]\n",
    "    macro['DAX'] = pd.DataFrame(yf.download('^DAX-EU', date.today())).Close[0]\n",
    "    macro['NI225'] = pd.DataFrame(yf.download('^N225', date.today())).Close[0]\n",
    "    macro['Gold'] = pd.DataFrame(yf.download('GC=F', date.today())).Close[0]\n",
    "    macro['Bitcoin'] = pd.DataFrame(yf.download('BTC-USD', date.today())).Close[0]\n",
    "    macro['USD/EUR'] = pd.DataFrame(yf.download('EUR=X', date.today())).Close[0]\n",
    "    macro['USD/GBP'] = pd.DataFrame(yf.download('GBP=X', date.today())).Close[0]\n",
    "    macro['USD/CAD'] = pd.DataFrame(yf.download('CAD=X', date.today())).Close[0]\n",
    "    macro['USD/JPY'] = pd.DataFrame(yf.download('JPY=X', date.today())).Close[0]\n",
    "    macro['USD/CNY'] = pd.DataFrame(yf.download('CNY=X', date.today())).Close[0]\n",
    "    macro['USD/AUD'] = pd.DataFrame(yf.download('AUD=X', date.today())).Close[0]\n",
    "    macro['USD/MXN'] = pd.DataFrame(yf.download('MXN=X', date.today())).Close[0]\n",
    "    write_macro_economics(macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Libor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Update certain macro-economic row with Overnight Libor rate\n",
    "def write_libor(df):\n",
    "    try:\n",
    "        #Create connection with database\n",
    "        connection = get_connection()\n",
    "        cursor = connection.cursor()\n",
    "        update_query = \"\"\"update macro_economic set libor = %s where date = %s\"\"\"\n",
    "        value = float(str(df['Euro LIBOR - overnight'][1]).rstrip('%'))\n",
    "        cursor.execute(update_query, (value, df[df.columns[-1]][1]))\n",
    "        update_gdp = \"\"\"update macro_economic set gdp = %s where date = %s\"\"\"\n",
    "        cursor.execute(update_gdp, (-0.314, df[df.columns[-1]][1]))\n",
    "        connection.commit()\n",
    "        close_connection(connection)\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while getting data \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scrapes global-rates.com to extract libor rates\n",
    "def scrape_libor_main():\n",
    "    url = 'https://www.global-rates.com/en/interest-rates/libor/libor.aspx'\n",
    "    r = requests.get(url)\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find('table', {\"style\": \"width:100%;margin:10px 0px 0px 0px;border:1px solid #CCCCCC;\"})\n",
    "    rows = table.find_all('tr')\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele])\n",
    "\n",
    "    result = pd.DataFrame(data)\n",
    "    result = result.transpose()\n",
    "    result.head()\n",
    "    result = result.drop([2,6,7,9,10,11,12,13], axis = 1)\n",
    "    result['date'] = date.today() + timedelta(-1)\n",
    "    result['date'][2] = date.today() + timedelta(-2)\n",
    "    result['date'][3] = date.today() + timedelta(-3)\n",
    "    result['date'][4] = date.today() + timedelta(-4)\n",
    "    result['date'][5] = date.today() + timedelta(-5)\n",
    "    #grab the first row for the header\n",
    "    new_header = result.iloc[0]\n",
    "    #take the data less the header row\n",
    "    result = result[1:]\n",
    "    result.columns = new_header\n",
    "    write_libor(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_fundamentals(ticker ,d):\n",
    "    yesterday = datetime.datetime.today() + timedelta(-1)\n",
    "    try:\n",
    "        connection = get_connection()\n",
    "        cursor = connection.cursor()\n",
    "        postgres_insert_query = \"\"\" INSERT INTO fundamentals (ticker, date , previousclose, regularmarketopen,\n",
    "        twoHundredDayAverage , trailingAnnualDividendYield, payoutRatio , regularMarketDayHigh, averageDailyVolume10Day, regularMarketPreviousClose,\n",
    "        fiftyDayAverage,trailing_Annual_Dividend_Rate, averageVolume10days, dividendRate , beta,\n",
    "        regularMarketDayLow, trailing_PE, regularMarketVolume, marketCap, averageVolume,\n",
    "        price_to_sales_12months, dayLow, ytdReturn, askSize, fiftyTwo_Week_High, forwardPE,\n",
    "        five_years_average_dividend_yield, ask, bid,  fiftyTwoWeekLow, dividendYield, bidSize, dayHigh,\n",
    "        entreprise_to_revenue, beta3Year, profitMargins, entreprise_to_ebitda , fiftytwoweekchange,\n",
    "        forwardEps, shares_outstanding, bookValue, shares_short,\n",
    "        shares_Percent_Shares_Out, last_Fiscal_Year_End, held_Percent_Institutions, net_Income_To_Common, trailing_Eps, SandP_fiftytwo_Week_Change,\n",
    "        price_To_Book, held_Percent_Insiders, next_Fiscal_Year_End, most_Recent_Quarter, short_Ratio, shares_Short_Previous_Month_Date,\n",
    "        float_Shares, enterprise_Value, three_Year_Average_Return, date_Short_Interest,\n",
    "       peg_Ratio, short_Percent_Of_Float, shares_Short_Prior_Month, five_Year_Average_Return, regular_Market_Price) VALUES (%s,%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s,%s, %s,%s,%s,%s,%s,%s,%s,%s )\"\"\"\n",
    "        record_to_insert = (ticker ,yesterday, d.get(\"previousClose\") ,d.get(\"regularMarketOpen\"), d.get(\"twoHundredDayAverage\"),\n",
    "        d.get(\"trailingAnnualDividendYield\"), d.get(\"payoutRatio\"), d.get(\"regularMarketDayHigh\"), d.get('averageDailyVolume10Day'),d.get('regularMarketPreviousClose'), d.get('fiftyDayAverage'),\n",
    "        d.get('trailingAnnualDividendRate'), d.get('averageVolume10days'),d.get( 'dividendRate')  , d.get('beta'), d.get('regularMarketDayLow'), d.get('trailingPE'), d.get('regularMarketVolume'), d.get('marketCap'), d.get('averageVolume'),\n",
    "        d.get('priceToSalesTrailing12Months'), d.get('dayLow'), d.get('ytdReturn'), d.get('askSize'), d.get('fiftyTwoWeekHigh'), d.get('forwardPE'),\n",
    "        d.get('fiveYearAvgDividendYield'), d.get('ask'), d.get('bid'),  d.get('fiftyTwoWeekLow'), d.get('dividendYield'), d.get('bidSize'), d.get('dayHigh'),\n",
    "        d.get('enterpriseToRevenue'), d.get('beta3Year'), d.get('profitMargins'), d.get('enterpriseToEbitda') , d.get('52WeekChange'),\n",
    "        d.get('forwardEps'), d.get('sharesOutstanding'), d.get('bookValue'), d.get('sharesShort'), d.get('sharesPercentSharesOut'), d.get('lastFiscalYearEnd') , d.get('heldPercentInstitutions'), d.get('netIncomeToCommon'), d.get('trailingEps'), d.get('SandP52WeekChange'),\n",
    "        d.get('priceToBook'), d.get('heldPercentInsiders'), d.get('nextFiscalYearEnd'), d.get('mostRecentQuarter'), d.get('shortRatio'), d.get('sharesShortPreviousMonthDate'),\n",
    "        d.get('floatShares'), d.get('enterpriseValue'), d.get('threeYearAverageReturn'), d.get('dateShortInterest'), d.get('pegRatio'), d.get('shortPercentOfFloat'), d.get('sharesShortPriorMonth'), d.get('fiveYearAverageReturn'), d.get('regularMarketPrice'))\n",
    "        cursor.execute(postgres_insert_query,record_to_insert)\n",
    "        connection.commit()\n",
    "        close_connection(connection)\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while getting data \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_fundamentals_main():\n",
    "    for t in get_tickers():\n",
    "        try:\n",
    "            tck = yf.Ticker(t)\n",
    "            d = tck.get_info()\n",
    "            write_fundamentals(t, d)\n",
    "        except IndexError :\n",
    "            print('Index error for {}'.format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Financials\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "\n",
      " Downloading Fundamentals \n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "\n",
      " Download Macro-Economic Data \n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Postgres connection is closed\n",
      "Postgres connection is closed\n",
      "\n",
      " Done for today (2020-12-23 08:04:48.102790)\n"
     ]
    }
   ],
   "source": [
    "print('Downloading Financials')\n",
    "#Write all financials to financials table\n",
    "financials_main() #Prints out failed tickers\n",
    "\n",
    "print('\\n Downloading Fundamentals ')\n",
    "#Write all fundamentals to fundamentals table\n",
    "scrape_fundamentals_main()\n",
    "#Print out failed tickers\n",
    "\n",
    "print('\\n Download Macro-Economic Data ')\n",
    "#Update created macro-economic table\n",
    "macro_economic_main()\n",
    "#Update created macro-economic table\n",
    "scrape_libor_main()\n",
    "\n",
    "print('\\n Done for today ({})'.format(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
